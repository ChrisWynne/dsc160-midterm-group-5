{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify API Scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this once\n",
    "#!pip install spotipy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_credentials(api_cred_fp):\n",
    "    if os.path.exists(api_cred_fp):\n",
    "        with open(api_cred_fp) as json_file:\n",
    "            creds = json.load(json_file)\n",
    "        return creds\n",
    "    else:\n",
    "        \"Credentials File Not Found\"\n",
    "\n",
    "def load_cached_requests(fp,is_master):\n",
    "    if os.path.exists(fp):\n",
    "        with open(fp) as json_file:\n",
    "            ret_dic = json.load(json_file)\n",
    "            print(\"Loaded cached data at:\",fp)\n",
    "    else:\n",
    "        print(\"Failed to load cached data at:\",fp)\n",
    "        ret_dic = {}\n",
    "        if is_master:\n",
    "            ret_dic['master_tracks'] = {}\n",
    "            ret_dic['master_playlists'] = {}\n",
    "            ret_dic['master_audio_features'] = {}\n",
    "            ret_dic['playlist_tracks'] = {}\n",
    "            \n",
    "    return ret_dic\n",
    "\n",
    "def save_cached_requests(save_dic, save_dir,fname):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    with open(save_dir+fname,'w+') as outfile:\n",
    "        json.dump(save_dic,outfile)\n",
    "\n",
    "def save_csvs(df_list,dir_list,fname_list):\n",
    "    if len(df_list) == len(dir_list) == len(fname_list):\n",
    "        for i in range(len(df_list)):\n",
    "            cur_df = df_list[i]\n",
    "            cur_dir = dir_list[i]\n",
    "            cur_fname = fname_list[i]\n",
    "            if not os.path.exists(cur_dir):\n",
    "                os.makedirs(cur_dir)\n",
    "            cur_df.to_csv(cur_dir+cur_fname,index=False)\n",
    "            print(\"CSV Saved at:\",cur_dir+cur_fname)\n",
    "    else:\n",
    "        print(\"Save Failed: List lengths must be the same\")\n",
    "\n",
    "def save_csv(df, save_dir, fname):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    df.to_csv(save_dir + fname,index=False)\n",
    "    print(\"CSV Saved at:\",save_dir+fname)\n",
    "    \n",
    "def get_playlists_data_from_category(cat_id,master_playlist_dic,sp,playlist_tracks_dic,master_track_dic):\n",
    "    # api call\n",
    "    search_result = sp.category_playlists(category_id=cat_id,limit=50,country=\"US\")\n",
    "    playlist_ids = []\n",
    "    for playlist in search_result['playlists']['items']:\n",
    "        playlist_ids.append(playlist['id'])\n",
    "    playlists_data = []\n",
    "    # updates the playlist dic with info about playlist\n",
    "    for playlist_id in playlist_ids:\n",
    "        # avoids api call using cached request, could hold outdated info if playlist is changed recently\n",
    "        if playlist_id in master_playlist_dic.keys():\n",
    "            playlist_data = master_playlist_dic[playlist_id]\n",
    "        else:\n",
    "            # api call\n",
    "            playlist_data = sp.playlist(playlist_id)\n",
    "            # update master playlist dic with playlist data\n",
    "            master_playlist_dic[playlist_id] = playlist_data\n",
    "        playlists_data.append(playlist_data)\n",
    "    # updates the playlist track dic with all of the track ids in the playlist\n",
    "    all_playlists_tracks = []\n",
    "    for playlist_id in playlist_ids:\n",
    "        cur_playlist_tracks = get_full_playlist_tracks(playlist_tracks_dic, playlist_id, \n",
    "                                                       master_playlist_dic, master_track_dic,sp)\n",
    "        \n",
    "        all_playlists_tracks.extend(cur_playlist_tracks)\n",
    "    return all_playlists_tracks\n",
    "\n",
    "def get_track_data_from_playlists(genre_tracks,master_audio_features_dic,\n",
    "                                  sp,master_playlist_dic):\n",
    "    timed_out = False\n",
    "    ret_df = pd.DataFrame()\n",
    "    valid_genre_track_ids = []\n",
    "    for cur_track_id in genre_tracks:\n",
    "        if cur_track_id != None:\n",
    "            valid_genre_track_ids.append(cur_track_id)            \n",
    "                \n",
    "    # making a list of non cached track audio features\n",
    "    not_cached_ids = []\n",
    "    for track_id in valid_genre_track_ids:\n",
    "        if track_id not in master_audio_features_dic.keys():\n",
    "            not_cached_ids.append(track_id)\n",
    "\n",
    "    # get audio features of non cached tracks\n",
    "    if len(not_cached_ids) > 0:\n",
    "        split_not_cached_ids = [not_cached_ids[x:x+80] for x in range(0,len(not_cached_ids),80)]\n",
    "        not_cached_data = []\n",
    "        print(\"Making\",len(not_cached_ids),\"API Calls\")\n",
    "        for batch_ids in split_not_cached_ids:\n",
    "            try:\n",
    "                # api call\n",
    "                not_cached_data.extend(sp.audio_features(batch_ids))\n",
    "                time.sleep(2)\n",
    "            except:\n",
    "                print(\"Error getting audio features, retrying...\")\n",
    "                timed_out = True\n",
    "                time.sleep(10)\n",
    "            err_count = 0\n",
    "            while timed_out:\n",
    "                try:\n",
    "                    not_cached_data.extend(sp.audio_features(batch_ids))\n",
    "                    timed_out=False\n",
    "                except:\n",
    "                    if err_count > 5:\n",
    "                        print(\"Too many errors\")\n",
    "                        raise\n",
    "                    else:\n",
    "                        print(\"Error getting audio features, retrying...\")\n",
    "                        time.sleep(10*(err_count+1))\n",
    "                        err_count += 1\n",
    "        # caching the non cached track audio features\n",
    "        for i in range(len(not_cached_data)):\n",
    "            track_feats = not_cached_data[i]\n",
    "            if track_feats:\n",
    "                master_audio_features_dic[track_feats['id']] = track_feats\n",
    "            else:\n",
    "                master_audio_features_dic[not_cached_ids[i]] = None\n",
    "\n",
    "    # iterating current playlist tracks and accessing the cached audio features\n",
    "    playlist_track_feats = []\n",
    "    for track_id in valid_genre_track_ids:\n",
    "        cur_feats = master_audio_features_dic[track_id]\n",
    "        if cur_feats:\n",
    "            playlist_track_feats.append(cur_feats)\n",
    "\n",
    "    # building return df\n",
    "    genre_df = pd.DataFrame(playlist_track_feats)\n",
    "    return genre_df\n",
    "\n",
    "def main_scrape(cat_ids,csv_save_dir,csv_fname,cred_fp,cache_dir,all_requests_fname):\n",
    "    # initializing vars\n",
    "    creds = get_credentials(cred_fp)\n",
    "    client_id = creds['client_id']\n",
    "    client_secret = creds['client_secret']\n",
    "    client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "    sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "    all_requests_dic = load_cached_requests(cache_dir + all_requests_fname,is_master=True)\n",
    "    master_track_dic = all_requests_dic['master_tracks']\n",
    "    master_playlist_dic = all_requests_dic['master_playlists']\n",
    "    master_audio_features_dic = all_requests_dic['master_audio_features']\n",
    "    playlist_tracks_dic = all_requests_dic['playlist_tracks']\n",
    "    \n",
    "    master_df = pd.DataFrame()\n",
    "    for cat_id in cat_ids:\n",
    "        cat_tracks = get_playlists_data_from_category(cat_id,master_playlist_dic,sp,\n",
    "                                                      playlist_tracks_dic,master_track_dic)\n",
    "        \n",
    "        cat_df = get_track_data_from_playlists(cat_tracks,master_audio_features_dic,\n",
    "                                               sp,master_playlist_dic)\n",
    "        cat_df['genre(s)'] = cat_id\n",
    "        master_df = pd.concat([master_df,cat_df])\n",
    "        print(\"Caching \" + cat_id + \" requests...\")\n",
    "        # may not save new requests to the master cache dic, need to confirm/deny\n",
    "        save_cached_requests(all_requests_dic,cache_dir,all_requests_fname)\n",
    "        \n",
    "    # cleaning master df    \n",
    "    master_df = master_df.drop_duplicates(subset=['id','genre(s)'])\n",
    "    master_df = master_df.reset_index(drop=True)\n",
    "    master_df = master_df.drop(['type','track_href','uri'],axis=1)\n",
    "    master_df = get_track_metadata(master_df,master_track_dic).reset_index(drop=True)\n",
    "    \n",
    "    # write df to disk\n",
    "    save_csv(master_df,csv_save_dir,csv_fname)\n",
    "    return master_df\n",
    "\n",
    "def get_full_playlist_tracks(playlist_tracks_dic, cur_id, master_playlist_dic,master_track_dic,sp):\n",
    "    timed_out = False\n",
    "    if cur_id in playlist_tracks_dic.keys():\n",
    "        print(\"already cached playlist\",cur_id)\n",
    "    else:\n",
    "        time.sleep(.5)\n",
    "        print(\"Scraping playlist\",cur_id)\n",
    "        playlist_tracks_dic[cur_id] = []\n",
    "        # first run\n",
    "        cur_playlist_items = master_playlist_dic[cur_id]['tracks']['items']\n",
    "        cur_tracks = []\n",
    "        for cur_track in cur_playlist_items:\n",
    "            if cur_track and cur_track['track'] and cur_track['track']['id']:\n",
    "                cur_tracks.append(cur_track['track']['id'])\n",
    "                # updating master track dic for initial 100 songs\n",
    "                if cur_track['track']['id'] not in master_track_dic.keys():\n",
    "                    master_track_dic[cur_track['track']['id']] = cur_track\n",
    "        playlist_tracks_dic[cur_id].extend(cur_tracks)\n",
    "        # get entire playlist\n",
    "        total_songs = master_playlist_dic[cur_id]['tracks']['total']\n",
    "        cur_data = master_playlist_dic[cur_id]['tracks']\n",
    "        \n",
    "        # getting the rest of the track ids (init batch is only first 100 playlist songs)\n",
    "        while len(playlist_tracks_dic[cur_id]) < total_songs:  \n",
    "            # initial attempt\n",
    "            try:\n",
    "                next_data = sp.next(cur_data)\n",
    "            except:\n",
    "                print(\"Error getting playlist tracks, retrying...\")\n",
    "                timed_out = True\n",
    "                time.sleep(10)\n",
    "            # retries if initial attempt fails\n",
    "            err_count = 0\n",
    "            while timed_out:\n",
    "                try:\n",
    "                    next_data = sp.next(cur_data)\n",
    "                    timed_out=False\n",
    "                except:\n",
    "                    if err_count > 5:\n",
    "                        print(\"Too many failed attempts\")\n",
    "                        raise\n",
    "                    else:\n",
    "                        print(\"Error getting playlist tracks, retrying...\")\n",
    "                        time.sleep(10*(err_count+1))\n",
    "                        err_count += 1\n",
    "            cur_tracks = []\n",
    "            cur_playlist_items = cur_data['items']\n",
    "            for cur_track in cur_playlist_items:\n",
    "                if cur_track and cur_track['track'] and cur_track['track']['id']:\n",
    "                    cur_tracks.append(cur_track['track']['id'])\n",
    "                    # updating master track dic for latter 100+ songs\n",
    "                    if cur_track['track']['id'] not in master_track_dic.keys():\n",
    "                        master_track_dic[cur_track['track']['id']] = cur_track\n",
    "            playlist_tracks_dic[cur_id].extend(cur_tracks)         \n",
    "            cur_data = next_data\n",
    "            time.sleep(2)\n",
    "            print(\"Songs gathered:\",len(playlist_tracks_dic[cur_id]),\"of\",total_songs)\n",
    "    playlist_tracks_dic[cur_id] = list(set(playlist_tracks_dic[cur_id])) # remove duplicates\n",
    "    return playlist_tracks_dic[cur_id]\n",
    "\n",
    "def get_track_metadata(df,tracks_dic):\n",
    "    # getting metadata for each track\n",
    "    artist_ids = []\n",
    "    track_names = []\n",
    "    artist_names = []\n",
    "    for targ_track_id in df['id']: \n",
    "        if targ_track_id in tracks_dic.keys():\n",
    "            track_data = tracks_dic[targ_track_id]['track']\n",
    "            track_name = track_data['name']\n",
    "            track_names.append(track_name)\n",
    "            artists = track_data['artists']\n",
    "            artists_string = \"\"\n",
    "            artists_names_string = \"\"\n",
    "            for i in range(len(artists)):\n",
    "                if 'name' in artists[i].keys() and artists[i]['name']:\n",
    "                    if i == len(artists) - 1:\n",
    "                        artists_names_string += artists[i]['name']\n",
    "                    else:\n",
    "                        artists_names_string += artists[i]['name'] + \"//\"\n",
    "                if 'id' in artists[i].keys() and artists[i]['id']:\n",
    "                    if i == len(artists) - 1:\n",
    "                        artists_string += artists[i]['id']\n",
    "                    else:\n",
    "                        artists_string += artists[i]['id'] + \"//\"\n",
    "            artist_names.append(artists_names_string)\n",
    "            artist_ids.append(artists_string)\n",
    "        else:\n",
    "            artist_ids.append(np.nan)\n",
    "    df['artist_ids'] = artist_ids\n",
    "    df['artist_names'] = artist_names\n",
    "    df['name'] = track_names\n",
    "    # accounts for multiple genres (aka same song in different genre playlists)\n",
    "    df['genre(s)'] = df['id'].apply(lambda x:\"//\".join(df[df['id'] == x]['genre(s)'].values))\n",
    "    df = df.drop_duplicates(subset='id') # new duplicates created after combining genres\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = ['kpop','pop','rock','hiphop','reggae','jazz','rnb','classical','country','edm_dance']\n",
    "audio_features_dir = \"../data/test/all/metadata/\"\n",
    "audio_features_fname = \"all_audio_features.csv\"\n",
    "cred_fp = \"../api_cred.json\"\n",
    "cache_dir = \"../data/local/cached_requests/\"\n",
    "all_requests_fname = \"all_requests.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = main_scrape(genres,audio_features_dir,audio_features_fname,cred_fp,cache_dir,all_requests_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work in Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possibly iterate albums from the category or search result playlists for the genre key word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easy startup\n",
    "all_requests_dic = load_cached_requests(cache_dir + all_requests_fname,True)\n",
    "master_track_dic = all_requests_dic['master_tracks']\n",
    "playlist_tracks_dic = all_requests_dic['playlist_tracks']\n",
    "master_playlist_dic = all_requests_dic['master_playlists']\n",
    "master_audio_features_dic = all_requests_dic['master_audio_features']\n",
    "\n",
    "creds = get_credentials(cred_fp)\n",
    "client_id = creds['client_id']\n",
    "client_secret = creds['client_secret']\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = sp.categories(country=\"US\",limit=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in cats['categories']['items']:\n",
    "    print(cat['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['reggae','jazz','rnb','classical','country','edm_dance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # takes like 30 sec\n",
    "# df['genre(s)'] = df['id'].apply(lambda x:\"//\".join(df[df['id'] == x]['genre(s)'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop_duplicates(subset='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['genre(s)'].apply(lambda x: \"//\" in x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genres = df[]['genre(s)'].value_counts().index\n",
    "# genres_string = \"\"\n",
    "# for i in range(len(genres)):\n",
    "#     if i == len(genres) - 1:\n",
    "#         genres_string += genres[i]\n",
    "#     else:\n",
    "#         genres_string += genres[i] + \"//\"\n",
    "# genres_string    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = sp.track(\"3qqcavKhQkzyyqGC5UDIAL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test1():\n",
    "#     main_dic = {\"test\": {\"sub\":2}}\n",
    "#     test2(main_dic)\n",
    "#     print(main_dic)\n",
    "\n",
    "# def test2(main_dic):\n",
    "#     sub_dic = main_dic['test']\n",
    "#     sub_dic['sub'] = 1\n",
    "# test1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(tracks_dic.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_requests_dic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# playlist_data = all_requests_dic['master_playlists']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_result = sp.category_playlists(category_id=\"rock\",limit=50,country=\"US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_result['playlists']['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in search_result['playlists']['items']:\n",
    "#     print(p['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# playlist_data[\"37i9dQZF1DX5JcPJgYjGcf\"]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t in playlist_data[\"37i9dQZF1DX5JcPJgYjGcf\"]['tracks']['items']:\n",
    "#     print(t['track']['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df['artist_ids'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not_in[0]\n",
    "# track_data = sp.tracks(not_in[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# playlist_dic = all_requests_dic['master_playlists']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_data = sp.next(playlist_dic['660VrDfeGlKRFkMDy15JP0']['tracks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_data['items'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for track in next_data['items']:\n",
    "#     if track['id']:\n",
    "#         master_track_dic[track['id']] = track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_track_dic = load_cached_requests(cache_dir + master_track_fname)\n",
    "# master_playlist_dic = load_cached_requests(cache_dir + master_playlist_fname)\n",
    "# master_audio_features_dic = load_cached_requests(cache_dir + master_audio_features_fname)\n",
    "# playlist_tracks_dic = load_cached_requests(cache_dir + playlist_tracks_fname)\n",
    "# all_requests_dic = {\"playlist_tracks\": playlist_tracks_dic, \"master_tracks\":master_track_dic, \n",
    "#                     \"master_playlists\":master_playlist_dic, \"master_audio_features\": master_audio_features_dic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_cached_requests(all_requests_dic,cache_dir,all_requests_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# playlist_tracks_dic = load_cached_requests(cache_dir + playlist_tracks_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = 0\n",
    "# unique = []\n",
    "# for p in playlist_tracks_dic.keys():\n",
    "#     print(len(playlist_tracks_dic[p]))\n",
    "#     for track in playlist_tracks_dic[p]:\n",
    "#         if track in unique:\n",
    "#             continue\n",
    "#         else:\n",
    "#             unique.append(track)\n",
    "# len(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = [1]*1234\n",
    "# split = [temp[x:x+100] for x in range(0,len(temp),100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in df.columns:\n",
    "#     print(col, len(df[df[col].apply(lambda x: x == -1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_result = sp.category_playlists(category_id=\"kpop\",country=\"US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_result['playlists'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_playlist_dic['660VrDfeGlKRFkMDy15JP0']['tracks']['items'][98]['track']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kpop_playlists_data = get_playlists_data_from_category(\"kpop\",master_playlist_dic)\n",
    "# kpop_df = get_track_data_from_playlists(pop_playlists_data, master_track_dic,master_audio_features_dic)\n",
    "\n",
    "# pop_playlists_data = get_playlists_data_from_category(\"pop\",master_playlist_dic)\n",
    "# pop_df = get_track_data_from_playlists(pop_playlists_data, master_track_dic,master_audio_features_dic)\n",
    "\n",
    "# rock_playlists_data = get_playlists_data_from_category(\"rock\",master_playlist_dic)\n",
    "# rock_df = get_track_data_from_playlists(rock_playlists_data, master_track_dic,master_audio_features_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_cached_requests(master_track_dic,cache_dir,master_track_fname)\n",
    "# save_cached_requests(master_playlist_dic,cache_dir,master_playlist_fname)\n",
    "# save_cached_requests(master_audio_features_dic,cache_dir,master_audio_features_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rock_df['genre'] = 'rock'\n",
    "# pop_df['genre'] = 'pop'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kpop_csv_dir = \"../data/test/kpop/metadata/\"\n",
    "# kpop_fname = \"kpop_metadata.csv\"\n",
    "\n",
    "# pop_csv_dir = \"../data/test/pop/metadata/\"\n",
    "# pop_fname = \"pop_metadata.csv\"\n",
    "\n",
    "# rock_csv_dir = \"../data/test/rock/metadata/\"\n",
    "# rock_fname = \"rock_metadata.csv\"\n",
    "\n",
    "# dfs = [kpop_df,pop_df,rock_df]\n",
    "# csv_dirs = [kpop_csv_dir,pop_csv_dir,rock_csv_dir]\n",
    "# csv_fnames = [kpop_fname,pop_fname,rock_fname]\n",
    "\n",
    "# save_csvs(dfs,csv_dirs,csv_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis_df = pd.read_csv(\"../data/test/kpop/metadata/kpop_metadata.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
